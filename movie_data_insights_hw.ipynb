{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f5299d-77da-41f7-b85e-b07244c0c5cc",
   "metadata": {},
   "source": [
    "<center><img src = \"https://images.unsplash.com/photo-1502033491742-0e11fb057e16?q=80&w=1332&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\" width=\"1200\" height=\"600\"/></center>\n",
    "\n",
    "<center> photo credit: Julien Andrieux - Unsplash </center>\n",
    "\n",
    "# Movie Data - Programmatic Data Handling\n",
    "## *Harry Webber*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb99c99-73cc-4e7e-b569-e19b6dda0c53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b44f59-36ea-40e6-8f24-af4e8aa4b374",
   "metadata": {},
   "source": [
    "Firstly, we need to import the python libraries that we will need for the data handling and visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc1cf2-49b1-4136-abb6-6b96b6e5b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                # numpy! for mathematical operations\n",
    "import seaborn as sns             # creating visualisations!\n",
    "import matplotlib.pyplot as plt   # customising visualisations!\n",
    "import pandas as pd               # dataframes & data analysis! -- general data use!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363d891-65aa-4262-afcf-1e27a1f2678e",
   "metadata": {},
   "source": [
    "We then import the dataset using pandas and save it as our dataframe for the data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31c0ed-0dcc-41d0-8904-831ddfa5c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe called df and read in the csv from the local file\n",
    "df = pd.read_csv('TMDB_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667d805-d041-4b6e-be66-a27377aed0c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Initial Dataframe Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd85034-0c50-4f35-9f43-9dbe8dd8740f",
   "metadata": {},
   "source": [
    "### 2.1 Shape of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032bf7b-24df-4d13-b1d0-c4c0c57d1074",
   "metadata": {},
   "source": [
    "We inspect the shape of the dataframe (how many rows and columns) and the first rows of the dataframe (using the `.head()` method) to understand what columns there are and what information is present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9969418-90ca-4b02-8ca7-928e973bc585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e982f0-e63a-48f6-ac04-911a03dde5dc",
   "metadata": {},
   "source": [
    "> We find that there are 4803 rows/entries and 20 columns in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc67ca2-6dfe-4034-a330-ba0dfb2853ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed843134-dbb2-4188-8fab-afd24d7d5602",
   "metadata": {},
   "source": [
    "My initial impressions, having inspected the dataframe are as follows:\n",
    "1. The columns below are formatted in a manner that is not yet useful - seems to be some kind of nested dictionary...\n",
    "    * 'genres'\n",
    "    * 'keywords'\n",
    "    * 'production_companies'\n",
    "    * 'production_countries'\n",
    "    * 'spoken_languages'\n",
    "2. We also want to inspect the number of null values in each column of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b74db-c195-45a2-b714-c515482bdefc",
   "metadata": {},
   "source": [
    "### 2.2 Check for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b895d7-ec2a-409b-afa3-93356ac1895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()    ## count the nulls in each column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf14976-fc27-4f97-be48-286306a69cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_vals(dataframe):                                                 ## This function is copied from earlier in the training programme to show the percentage of missing data by column \n",
    "    null_vals = dataframe.isnull().sum()                                  ## How many nulls in each column\n",
    "    total_cnt = len(dataframe)                                            ## Total entries in the dataframe\n",
    "    null_vals = pd.DataFrame(null_vals,columns=['null'])                  ## Put the number of nulls in a single dataframe\n",
    "    null_vals['percent'] = round((null_vals['null']/total_cnt)*100,3)     ## Round how many nulls are there, as %, of the df\n",
    "    \n",
    "    return null_vals.sort_values('percent', ascending=False)\n",
    "\n",
    "null_vals(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1330c1d-b5c0-48cd-8c31-3a3582edee46",
   "metadata": {},
   "source": [
    "There are several columns involving null values and we will need to investigate or process them accordingly.\n",
    "* **'homepage'** has 3091 nulls - this is a large proportion (64%) of the data which we should not simply remove, since it could affect the findings dramatically.\n",
    "* **'overview'**, **'release_date'**, and **'runtime'** has 3, 1 and 2 nulls, respectively - we should investigate why this is but could remove these entries if required.\n",
    "* **'tagline'** has 844 null values - ideally we should not remove these (it is nearly 18% of the data) and should find an alternative method for handling these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508f182-fcde-4d5c-9214-6a1ae69aceff",
   "metadata": {},
   "source": [
    "I will first deal with the homepage 'column', then the 'tagline' and then the columns which have only 3 or fewer entries missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24d129-28de-4d43-8341-69038c943fb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Null Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933edaa8-65ff-4d45-b7f4-decd83814beb",
   "metadata": {},
   "source": [
    "### 3.1 Standard Fill: 'homepage' data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631a418-4a23-4e6e-a845-a8aea528743c",
   "metadata": {},
   "source": [
    "Since the 'homepage' column only shows a website link to the homepage of each respective film - which I am unlikley to need for the data exploration - I have decided to fill the nulls of that column with a \"flag\" (a placeholder value) to indicate that the entry is missing data. It appears that the column consists of strings or objects, so once I have double checked the datatype, I can this with a null placeholder value. I decide not to use padding or backfilling here, since there is no consistent relation between the separate entries in the dataframe. The flag I will use is simply 'X' - to show that the 'homepage' data was not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad331d-7bc9-481e-b5b2-8f39e659f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf787374-c2cd-48e7-80f5-419dac1e8f99",
   "metadata": {},
   "source": [
    "The datatype is indeed an object (holding website links) which should work using any text string as a placeholder for the missing data, so we go ahead will the flagging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f8b34-7315-4474-8bdc-c17174194c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['homepage'] = df['homepage'].fillna(\n",
    "    value = 'X', ## our value - this is called 'static filling!' - there is only 1 value\n",
    "    method = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69caa0-d297-4099-8460-cab7fef2b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_vals(df)  ## we now wish to confirm that there are no remaining NULL values in the 'homepage' column by running the previously defined function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff73858-4f72-480c-9813-ff2a90d2bcad",
   "metadata": {},
   "source": [
    "### 3.2 Standard Fill: 'tagline' data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa48bd0-7acb-4ec7-99f7-fbd11573e558",
   "metadata": {},
   "source": [
    "On further inspection of the dataframe, the tagline column simply holds a short tagline for the film - which may have appeared on a poster for example, since there are a large number **(844)** missing entries in this column, it would be very time consuming and inefficient to try to figure them out individually at this stage. Therefore, we will follow the same process that we just carried out for the 'homepage' column, filling the missing values with a placeholder value 'X', for consistent signalling of missing data across the two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093b59e-d25b-49d8-8bff-4acee8bfa898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tagline'] = df['tagline'].fillna(\n",
    "    value = 'X', ## our value - this is called 'static filling!' - there is only 1 value\n",
    "    method = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5265a1b2-8abd-4c1f-8ad5-78d371b16f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_vals(df)  ## we now wish to confirm that there are no remaining NULL values in the 'tagline' column by running the previously defined function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b587f-4ad3-47dd-8c8f-da112194573c",
   "metadata": {},
   "source": [
    "### 3.3 Dropping Nulls: 'overview', 'runtime', 'release_date'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70028d45-dcbc-4986-a428-6769cd8806a1",
   "metadata": {},
   "source": [
    "There are multiple options for handling the missing data in these columns.\n",
    "* I could \"custom fill\" the runtime and release date with the means of their respective genres, for example.\n",
    "* I could research and input an overview for those 3 entries.\n",
    "* I could drop the entries since it only accounts for about 1% of the data.\n",
    "\n",
    "Since this is just a single day data exploration task - I decide to just drop the remaining nulls in the interest of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c26e5-ba5b-48d7-94f9-23e5471349fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['overview'].isnull() | df['runtime'].isnull() | df['release_date'].isnull()]  ## we do a mask to check which entries are missing from these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeefcaa-4000-430a-9918-7ae24b22bd3b",
   "metadata": {},
   "source": [
    "It actually transpires that there is some overlap between the entries which have nulls in these columns, so rather than having to drop up to 6 entries from the dataframe, there are only 4 - **which is great!** We lose less data than expected!\n",
    "\n",
    "*However, I am concerned that there are entries in other columns which are also missing data - yet are not showing as null since they currently just have punctuation holding the value in their respective cells. This is something that we may need to investigate further later on in the data cleaning process.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ec55d-49fb-4bcf-9b7c-6d83a3f00be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(\n",
    "    axis = 0, # default is always to drop a row\n",
    "    how = 'any', # default - if you set to 'all' - would only drop if every value is NULL\n",
    "    subset = ['overview', 'runtime', 'release_date'],   # subset tells dropna which columns to consider\n",
    "    inplace = True # makes change permanent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508212c-a9fb-4bf0-ac86-465e938c7458",
   "metadata": {},
   "source": [
    "We have now dropped these null values and this affected the indexing on the dataframe since some have been removed, so we readjust this by reseting the index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb151c-489e-4af1-b189-615eb0fc7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()    # after dropping values to not have 'gaps'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a25b1b-e483-409a-97c2-d383253a64a2",
   "metadata": {},
   "source": [
    "Furthermore, we can now check for any remaining nulls in the initial dataframe... using the same `isnull()` method as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd136db-5bac-41f8-988e-2b21f96c0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455874f7-3ddc-4ad6-bc4c-8d22629c7974",
   "metadata": {},
   "source": [
    "**The dataframe now appears to be 'clean' - at least there are no null values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94d28c-7f20-4fd1-87cd-dfc840a09dfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Further Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98180c-7e2d-4e74-87e7-21d4f4fda579",
   "metadata": {},
   "source": [
    "I mentioned the following in the initial dataframe inspection section...\n",
    "> A number of columns are format in a manner that is not particularly useful - for example, involving extraneous punctuation marks, these include:\n",
    "**'genres', 'keywords', 'production_companies', 'production_countries', and 'spoken_languages'**\n",
    "\n",
    "I should now investigate this further before trying to interpret the data, since I have concerns that some of this consists of more missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ae07c-a6f7-4b1c-95f3-3e9db78a9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838663b3-8b45-45a2-ae77-e5bba1ef1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I can't actually see the full text of the cells here since they are too long to be displayed...\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)  # Shows full content of each cell\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07253d-17c8-4738-ae63-e4e516d3276b",
   "metadata": {},
   "source": [
    "Upon further inspection, I can see the following...\n",
    "* The 'genres' column contains information relating to a dictionary of genres, where each genre has its own ID\n",
    "* The 'keywords' column contains similar information but with a dictionary of keywords\n",
    "* The 'production_companies' is a dictionary of production companies\n",
    "* 'production_countries' and 'spoken_languages' are similarly dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced91756-d23e-4e26-b410-21f4b29fa344",
   "metadata": {},
   "source": [
    "> At this point, I needed some support from my manager in resolving these in a timely manner - he suggested that I could install the library 'ast' - standing for Abstract Syntax Tree - which allows you to format data of given code structures.\n",
    "> He also provided me with a function ('extract_genres') below, which helps with this process of parsing the data into an appropriate format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2906563-71ac-46b6-a26c-e661c4f238e7",
   "metadata": {},
   "source": [
    "### 4.1: Formatting the Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795932c-41e0-4d14-aa57-40e1d5073041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "ast.literal_eval(df.genres[0])[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbad86-dcdf-4cf3-b4a0-e692d78d9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genres(x):\n",
    "    ''' Function to extract genres for each datapoint. '''\n",
    "    x = ast.literal_eval(x) ## Transform '['name', 'id']' back into ['name', 'id']\n",
    "    Genres = [] ## Empty list to store the genres\n",
    "    \n",
    "    # Iterate through each dictionary\n",
    "    for item in x: ## iterate for each dictionary in our list\n",
    "        Genres.append(item['name']) ## Grab the 'name' key for each dictionary\n",
    "        \n",
    "    # Return the Genres\n",
    "    return Genres\n",
    "\n",
    "## Apply the function to genres\n",
    "df['extracted_genres'] = df['genres'].apply(extract_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7eedc8-9b2a-49ce-a2fc-15cc39b4cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913059e7-0876-4602-bb1f-6ef5ba8b6005",
   "metadata": {},
   "source": [
    "### 4.2: Formatting the Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601816bd-041e-46c1-ab55-9f65225bfb56",
   "metadata": {},
   "source": [
    "Since this was quite effective - we will try the same thing for the keywords and other columns involving these nested dictionary datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47626f63-a277-455a-96b4-cf882e1dd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyword(x):\n",
    "    ''' Function to extract keywords for each datapoint. '''\n",
    "    x = ast.literal_eval(x) ## Transform '['name', 'id']' back into ['name', 'id']\n",
    "    Keywords = [] ## Empty list to store the keywords\n",
    "    \n",
    "    # Iterate through each dictionary\n",
    "    for item in x: ## iterate for each dictionary in our list\n",
    "        Keywords.append(item['name']) ## Grab the 'name' key for each dictionary\n",
    "        \n",
    "    # Return the Keywords\n",
    "    return Keywords\n",
    "\n",
    "## Apply the function to keywords column\n",
    "df['extracted_keywords'] = df['keywords'].apply(extract_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037f879-7289-4a06-a494-165141aa905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() ## check the new column looks appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fde4da-35f6-41dc-bdf8-21e96ba0358f",
   "metadata": {},
   "source": [
    "### 4.3: Formatting the Production Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94be3af-a090-4db8-abce-64be9bec97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company(x):\n",
    "    ''' Function to extract production companies for each datapoint. '''\n",
    "    x = ast.literal_eval(x) ## Transform '['name', 'id']' back into ['name', 'id']\n",
    "    Companies = [] ## Empty list to store the Companies\n",
    "    \n",
    "    # Iterate through each dictionary\n",
    "    for item in x: ## iterate for each dictionary in our list\n",
    "        Companies.append(item['name']) ## Grab the 'name' key for each dictionary\n",
    "        \n",
    "    # Return the Companies\n",
    "    return Companies\n",
    "\n",
    "## Apply the function to production_companies column\n",
    "df['extracted_production_companies'] = df['production_companies'].apply(extract_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cdeb52-5527-45e1-b1a8-8a67d109e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534a7b7-db69-4910-be1a-60242936307a",
   "metadata": {},
   "source": [
    "### 4.4: Formatting the Production Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e656d-bbb1-4e93-bd26-93be4e450765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_country(x):\n",
    "    ''' Function to extract production countries for each datapoint. '''\n",
    "    x = ast.literal_eval(x) ## Transform '['name', 'id']' back into ['name', 'id']\n",
    "    Countries = [] ## Empty list to store the Countries\n",
    "    \n",
    "    # Iterate through each dictionary\n",
    "    for item in x: ## iterate for each dictionary in our list\n",
    "        Countries.append(item['name']) ## Grab the 'name' key for each dictionary\n",
    "        \n",
    "    # Return the Countries\n",
    "    return Countries\n",
    "\n",
    "## Apply the function to production_countries column\n",
    "df['extracted_production_countries'] = df['production_countries'].apply(extract_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de24a5-68ac-40e6-9d0b-fbc5bd2ce040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b676a-9a00-477f-9469-5e8b3a42b491",
   "metadata": {},
   "source": [
    "### 4.5: Formatting the Spoken Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74f5a4-b12e-46cd-adbe-d29e16bf53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_language(x):\n",
    "    ''' Function to extract spoken languages for each datapoint. '''\n",
    "    x = ast.literal_eval(x) ## Transform '['name', 'id']' back into ['name', 'id']\n",
    "    Languages = [] ## Empty list to store the Languages\n",
    "    \n",
    "    # Iterate through each dictionary\n",
    "    for item in x: ## iterate for each dictionary in our list\n",
    "        Languages.append(item['name']) ## Grab the 'name' key for each dictionary\n",
    "        \n",
    "    # Return the Languages\n",
    "    return Languages\n",
    "\n",
    "## Apply the function to spoken_languages column\n",
    "df['extracted_spoken_languages'] = df['spoken_languages'].apply(extract_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7fafb1-a655-45df-a916-78db516abb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1c13a-91ff-46b5-bec0-e615bcacc605",
   "metadata": {},
   "source": [
    "### 4.6: Dropping Unwanted Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd4a12-3cd1-4a55-9fa9-9a76637a4a79",
   "metadata": {},
   "source": [
    "Since the dataframe is getting quite crowded now with 5 additional columns, I will remove the original columns and keep the extracted information for use in data interpretation and visualisation stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb30249-f315-4c1a-b9ef-f3345bc43057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5e1f1-de76-407e-8382-78067eb5c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I also don't want the 'overview' column as there is a long string of text in this and it will not be particularly useful in the data visualisations I have in mind.\n",
    "\n",
    "df = df.drop(columns=['overview'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51876ff8-e7dc-4ee1-9ba7-46a7c19a2c11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f62ca-9ccd-40aa-82fa-ea8391ae5a90",
   "metadata": {},
   "source": [
    "### 5.1 Initial Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787a440-f0e1-4f56-b9ba-32b41554f0a6",
   "metadata": {},
   "source": [
    "To get a sense of what the data actually says, I will first use the `.describe()` method to see the summary statistics for each of the numeric datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d61d15-5c8f-4f84-9b31-12ea8f07b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715035d7-f900-4da0-ac22-5c78a2a5481e",
   "metadata": {},
   "source": [
    "My intial thoughts are as follows...\n",
    "* It is difficult to understand the **budget** and **revenue** columns since the numbers are large and not instantly simple to interpret - these will need further investigation.\n",
    "* The summary statistics for ID are probably not particularly helpful.\n",
    "* I don't fully understand the relationship between things like **vote_average** and **popularity** at this stage, but they seem to be similar metrics - just with vote_average being a score out of 10.\n",
    "* It may be interesting to filter/mask the popularity measures by those which have received at least a certain threshold of votes in **vote_count**.\n",
    "* It could also be interesting to investigate the runtime and see what impact this has on other metrics of the films (what film is 338 minutes long?!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b32bb-df52-403c-86ac-cdd0ec161192",
   "metadata": {},
   "source": [
    "### 5.2 Checking Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3cfc7f-ed3a-480e-8f28-aeb397d8af23",
   "metadata": {},
   "source": [
    "> Following this, it makes sense to check the correlations between some of these numeric metric within the dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea91be9-6b48-45be-a4b3-1c26167d4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, I select the columns which I wish to check for correlation between\n",
    "\n",
    "corr_values = df[['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']]   # all numeric columns except 'id'\n",
    "\n",
    "plt.figure(figsize = (8,8))                                                                      # set the figure size\n",
    "sns.heatmap(corr_values.corr(),                                                                  # I want to make a heatmap effectively showing a correlation matrix between these columns\n",
    "            annot = True,\n",
    "            fmt = '.1%',\n",
    "            cmap=sns.diverging_palette(0, 240, as_cmap=True),                                    # colour palette set to diverge from red to blue with red indicating negative correlation and blue indicating positive\n",
    "            vmin = -1, vmax = +1,\n",
    "            mask = np.triu(corr_values.corr()))                                                  # this masks it as a triangle to not show any duplicates or the diagonal where correlation = 1\n",
    "\n",
    "plt.title('Fig. 1: Correlation Heatmap', fontsize = 16)                                          # naming the plot\n",
    "plt.show()\n",
    "\n",
    "# If I instead wanted to save the chart as a .png file, I would use the following code\n",
    "# plt.savefig('movies_correlation_heatmap.png', dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46515114-cd6e-491a-8d9f-4fd734de81a8",
   "metadata": {},
   "source": [
    "> This correlation heatmap has no negative correlation at all - which is an interesting insight in itself - but the correlations do range from being basically trivial to quite strong.\n",
    "> * There are few surprises in the fact that **budget** is correlated with **revenue** since the film may include bigger 'stars' and have had more promotion.\n",
    "> * **Revenue** is correlated quite strongly with **popularity**, but there is weak correlation with **vote_average**.\n",
    "> * In fact, **vote_average** and **popularity** only share a weak correlation themselves which seems strange to me.\n",
    ">     * Both seem to be related to how good a film is.\n",
    ">     * However, I suppose a film can be popular without being highly rated.\n",
    ">     * Many 'blockbusters' or 'big comedy' films are purely for entertainment - but are quite poor aesthetically (this is sometimes even deliberate!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90510eaf-0064-4bed-a204-ce22e02e7ab4",
   "metadata": {},
   "source": [
    "### 5.3 Looking at Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2272582-0ad6-49cc-a14d-d51e17752b36",
   "metadata": {},
   "source": [
    "Since revenue is quite strongly correlated with budget, but also with things like vote_count and even popularity, I investigate the films by revenue first.\n",
    "\n",
    "> For this section:\n",
    "> * We define a new metric: 'performance ratio' as 'revenue over budget' (i.e. how many times its budget did it make?)\n",
    "> * We consider only the most voted films (those with over 5000 votes - top 84 in the dataframe) since they have at least been viewed by a statistically significant number of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539089b-2d11-4ab0-9192-d3339a08e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['performance_ratio'] = df['revenue'] / df['budget']     # How many times the film budget did it make in revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895bcb90-eb57-4a4b-922a-9369a281ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_voted = df[df['vote_count'] > 5000]                   # I am mainly interested here in films which many people have seen / have received a good number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44705d-fd90-4556-be0a-fa27dec0e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.regplot(data=most_voted, x='budget', y='revenue', color = \"green\", scatter_kws={\"color\": \"skyblue\"}, line_kws={\"color\": \"red\"}, ci = None)\n",
    "\n",
    "plt.xlabel('Movie Budget (100 Mil.)')\n",
    "plt.ylabel('Movie Revenue (Bil.)')\n",
    "\n",
    "plt.xlim(0, )                                                       # Set x-axis limits\n",
    "plt.ylim(0, )                                                       # Set y-axis limits\n",
    "\n",
    "plt.title('Fig. 2: Budget-Revenue Scatter Plot', fontsize = 16)     # naming the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892ae56-4519-4cde-bada-36792093469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.scatterplot(data=most_voted, x='budget', y='performance_ratio', hue = 'revenue')\n",
    "\n",
    "plt.xlabel('Movie Budget')\n",
    "plt.ylabel('Performance Ratio (Return on Budget)')                      # How many times the film budget did it make in revenue\n",
    "\n",
    "plt.xlim(0, )                                                           # Set x-axis limits\n",
    "plt.ylim(0, )                                                           # Set y-axis limits\n",
    "\n",
    "plt.title('Fig. 3: Performance against Budget', fontsize = 16)          # naming the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9709e-9901-4ca2-a0ad-6bd670d243eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_voted[most_voted['performance_ratio'] > 70]              # what is the outlier at the very top of this graph??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22934ec6-da53-4196-a450-fcea8daaba3d",
   "metadata": {},
   "source": [
    "#### Keypoint 1: Risk-Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac79958-9b01-4dda-ae28-32dbcb4ba76f",
   "metadata": {},
   "source": [
    "> * The film with the overall highest revenue (see fig. 2) is **Avatar**.\n",
    "> * This is also among the highest budget films in the dataframe.\n",
    "> * Rolling out a film with a large budget is a **big risk** for production companies as there are also many high budget films which don't yield such high revenue - i.e. \"commercial flops\".\n",
    "> * When we look at the fig. 3 - we see that there are a large number of lower budget films yielding huge performance ratios (i.e. high percentage profit).\n",
    "> * We should be careful here, since we have already masked to show only the top 84 most reviewed - many low budget films are unlikely to make it into this bracket.\n",
    "> * The uppermost point in fig. 3 - making over 70 times the budget of the film - and the film to make if you want to be successful in the film industry is..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5d7a7-ed22-45bc-b207-12e54ec1a437",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### surprise surprise..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e77f3-48bb-4f5b-a212-25bb5a1f2569",
   "metadata": {},
   "source": [
    "**<center>Star Wars</center>**\n",
    "\n",
    "<center><img src = \"https://images.unsplash.com/photo-1546561892-65bf811416b9?q=80&w=1170&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\" width=\"500\" height=\"400\"/></center>\n",
    "\n",
    "<center> photo credit: Tommy Van Kessel - Unsplash </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66d5c1-96bc-4731-91ac-7cd23977486c",
   "metadata": {},
   "source": [
    "So, if you want to make a commercially successful film, just make a film which will start a massive, decade-spanning franchise -- easy right?? ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f7dc7-d5c8-4081-a400-2bd206de62da",
   "metadata": {},
   "source": [
    "### 5.4 Which Films are Rated Highly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc38639-8040-44b3-aabb-ba37e77205ae",
   "metadata": {},
   "source": [
    "Looking back at the correlation heatmap - we also see that **vote_average** is not strongly correlated with any other metric in the dataframe. In fact the correlation coefficient is never more than 0.4 which indicates (at most) moderate correlation. So I am also interested to try to establish more about what makes certain films popular among the people who have voted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a72ce1-ab99-4e2a-ab54-aeab344b0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.histplot(data=df, x=\"vote_average\", binwidth = 0.2, color = \"skyblue\", kde=True)\n",
    "plt.xlim(0, 10)\n",
    "\n",
    "plt.title('Fig. 4: Distribution of Voting Scores', fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e4e62-7172-48ea-931d-476ee413444a",
   "metadata": {},
   "source": [
    "Looking at the distribution of films here - we see confirm that there is something close to a normal distribution with a mean just over 6. But I am interested at the moment in the highest rated films - so I will look at those with an average rating of over 8. Initially this creates a list of 50 films - however, some of these are quite niche and only have high ratings because they have so few voters anyway (maybe there are a few \"mega-fans\" but this is not really statistically significant). I want a set of films with the following restrictions...\n",
    "* Average rating (vote_average) is greater than 8.\n",
    "* Number of votes (vote_count) is greater than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a344985-4b9d-4ebf-95b4-1d212e5f0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_tier = df[(df['vote_average'] > 8) & (df['vote_count'] > 1000)]       # create a subset of the dataframe which only contains the films with ratings over 8 from over 1000 reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b202f9-177a-4b77-8d31-9ba65e7cfca2",
   "metadata": {},
   "source": [
    "Instinctively, I am intereseted to see if there is anything that these \"elite tier\" films have in common. I decided to look at the genres of the films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946bd1cc-d99e-4a08-ad16-968e8bc74768",
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_tier['extracted_genres'].value_counts()                               # check the genres of these top rated films"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33385c1a-16e8-47c9-9770-bfcac315a22b",
   "metadata": {},
   "source": [
    "Many of the films here have **'Drama'** as either a main genre - or one in a list of subgenres - this suggests that highly rated films are often in the 'Drama' genre. **Let's explore this a bit further...**\n",
    "\n",
    "I can do this by splitting the dataframe into those films which do have drama in the list of genres, and those which don't..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033254e-6530-45ac-b774-13e4f9300587",
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_mask = df['extracted_genres'].apply(lambda x: 'Drama' in x)                 # used a lambda function to iterate through the dataframe and find all films which have Drama as a genre\n",
    "drama_films = df[drama_mask].copy()                                               # used this as a mask on the dataframe\n",
    "\n",
    "non_drama_mask = df['extracted_genres'].apply(lambda x: 'Drama' not in x)         # repeat for those which do *not* have Drama as a genre\n",
    "non_drama_films = df[non_drama_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd946c-1079-448a-8d9f-d8b311cc163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_films.shape                # used this to check the number of films with drama as a genre - 2296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3e624-f0fd-4eb3-be34-a7eb87c68ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_drama_films.shape            # used this to check the number of films without drama as a genre - 2503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8290ba-f60c-4894-a7b9-097033fdfbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_films['is_drama'] = 'drama'                                                # created an extra column showing 'drama' if drama is one of the genres and 'not drama' if it is not\n",
    "non_drama_films['is_drama'] = 'not drama'\n",
    "\n",
    "# Concatenate these together into one dataframe for the visualisation -- ignore index argument creates a new consistent index ignoring the originals\n",
    "drama_df = pd.concat([drama_films, non_drama_films], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7d645-d674-4cde-b407-3779b7057529",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.boxplot(x='is_drama', y='vote_average', data=drama_df, color = 'skyblue', whis = 2.5)            # split the data by the new column 'is_drama' to make comparative boxplots\n",
    "\n",
    "plt.title('Fig. 5: Box Plots - Drama vs. Not Drama', fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eade24d-99c1-4392-bc74-14cc2312f3ef",
   "metadata": {},
   "source": [
    "#### Keypoint 2: Bring the Drama!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ccdf8-c612-4201-ac90-7e220bc2631a",
   "metadata": {},
   "source": [
    "> * Films which have 'drama' listed as a genre are consistently rated higher by voters than those which do not.\n",
    "> * Drama films have a median rating of **6.5** while non-drama films have a median rating of **6.0**.\n",
    "> * Drama films have a mean rating of **6.4** (1 d.p.) while non-drama have mean rating of **5.8** (1 d.p.).\n",
    "> * Drama films are also more consistently high rated with a lower range and interquartile range than the non-drama films.\n",
    "> * **We could say that if you want to make a highly rated film - make a drama** - but we should be careful about conflating the trend here with a direct causation.\n",
    "> * I do have some concerns about any films which are missing information on genre being bundled together - they may be low-budget / niche films - likely to be low rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a63bf-cd9f-419f-a99d-d193b0158686",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_drama_films['vote_average'].describe()   # for checking summary statistics of non-drama films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843226f-bcce-4634-8461-7ad4f5467b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_films['vote_average'].describe()   # for checking summary statistics of drama films"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfe914-f751-4816-8c96-213147f92080",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Single Observation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad53cd-8da5-44f9-96a5-b1ddf4f6e300",
   "metadata": {},
   "source": [
    "Since I haven't really yet had an opportunity to analyse the meaning of this 'popularity' metric - I will do so to some extent, by choosing the two \"most popular\" films according to this metric. They are **Minions** and **Interstellar**.\n",
    "\n",
    "<center><img src = \"https://images.unsplash.com/photo-1515041219749-89347f83291a?q=80&w=1074&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\" width=\"600\" height=\"500\"/></center>\n",
    "\n",
    "<center> photo credit: Justin Lim - Unsplash </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53102e8d-f46a-4277-b0ac-1703067316e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['popularity'] == df['popularity'].max()]       # find the most 'popular' film by this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade8b88-d4c4-4d6f-913e-3ba1c373531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['popularity'] > 700]                            # look at the films with over 700 popularity - I just played around with the numbers here a little after finding the max was minions with 875"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab46893-4103-499b-9151-222efb9e9c5c",
   "metadata": {},
   "source": [
    "When comparing these two films, there are a number of different insights to be made, the table below shows some of the key information and metrics of these two films from the dataframe...\n",
    "\n",
    "| Metric                                 | Interstellar                                                   | Minions                                     | Insights                                |\n",
    "| --------                               | --------                                                       | --------                                    | --------                                |\n",
    "| **Production Companies**               | Paramount - Legendary - Warner Bros. - Syncopy - Lynda Obst    | Universal - Illumination                    | Completely unique production            |\n",
    "| **Release Date**                       | 2014-11-05                                                     | 2015-06-17                                  | Similar year - different quarters       |\n",
    "| **Genre(s)**                           | Adventure - Drama - Science Fiction                            | Family - Animation - Adventure - Comedy     | Very different (but both 'Adventure')   |\n",
    "| **Budget**                             | 165,000,000                                                    | 74,000,000                                  | Interstellar more than double           |\n",
    "| **Revenue**                            | 675,120,017                                                    | 1,156,730,962                               | Both strong performers                  |\n",
    "| **Performance Ratio (1 d.p.)**         | 4.1                                                            | 15.6                                        | Minions was a huge commercial success   |\n",
    "| **Rating (vote_average)**              | 8.1                                                            | 6.4                                         | Interstellar top-rated                  |\n",
    "| **Number of Reviews (vote_count)**     | 10,867                                                         | 4571                                        | Maybe family/children review less       |\n",
    "\n",
    "> **<u>Interstellar**\n",
    "> * Clearly a very **highly rated** film with 8.1 average vote (among top 50 in dataset).\n",
    "> * Contextually we know that it is more **targeted at adults** (BBFC rated as a 12 [https://www.bbfc.co.uk/release/interstellar-q29sbgvjdglvbjpwwc0zode4nzi]).\n",
    "> * **Good revenue** making over 4 times its budget - but there was a relatively **high budget** initially.\n",
    "> * **Cast and crew** costs may have been high with stars like Matthew McConaughey, Anne Hathaway, Jessica Chastain and director: Christopher Nolan [https://www.imdb.com/title/tt0816692/].\n",
    ">\n",
    "> **<u>Minions**\n",
    "> * Not such a high rating (only just above average) and fewer votes. However, children are probably the main target audience and are unlikely to be voting.\n",
    "> * Being a **family film** and comedy means it has a broad audience - also better **potential for merchandise sales**.\n",
    "> * **Huge commercial success** with massive revenue and seems even better when we note that it made over 15 times the budget for the film.\n",
    "> * We should note that this was **not the first film in the 'Despicable Me' universe** and so production companies were likely to be confident in its popularity and success.\n",
    ">\n",
    "> **<u>Overall Comparison**\n",
    "> * **Commercially, Minions was the more successful film** in yielding massive revenue from a budget less than half that of Interstellar.\n",
    "> * **From a ratings perspective: Interstellar appears to have considerably higher reviews** and is in fact considered one of the best films in the dataset.\n",
    "> * Whilst they are both very different films stylistically, it is easy to see why both were popular in their own way.\n",
    "> * Also interesting to note that Minions was released in the Summer window (for school holidays?).\n",
    "> * Whereas, Interstellar was released in November (ahead of Christmas and potentially considering awards season)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
